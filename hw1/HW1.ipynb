{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import subprocess\n",
    "import tensorflow as tf\n",
    "import gym\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook, tqdm, trange\n",
    "from collections import defaultdict\n",
    "import load_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, InputLayer\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "experts = [\"Ant-v2\", \"HalfCheetah-v2\", \"Hopper-v2\", \"Humanoid-v2\", \"Reacher-v2\", \"Walker2d-v2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating expert data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runExpert(expert, rollouts) :\n",
    "    process = subprocess.Popen(\"python run_expert.py experts/{0}.pkl {1} --num_rollouts {2}\".format(expert, expert, rollouts), shell = True)\n",
    "    process.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rollouts = 20\n",
    "for expert in experts :\n",
    "    runExpert(expert, rollouts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting observations, actions from expert data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getExpertData(expert) :\n",
    "    with open(\"expert_data/{}.pkl\".format(expert), \"rb\") as f :\n",
    "        data = pickle.load(f)\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations and Actions :\n",
    "Observation is an array of shape (m, dim_obs) where m are the number of observations and dim_obs is the dimension of the observation array\n",
    "Action is an array of shape (m, 1, dim_act)\n",
    "\n",
    "For the Ant-v2 case, dim_obs = 111 and dim_act = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = getExpertData(\"Ant-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 111)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"observations\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 1, 8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"actions\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Behavior Cloning :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(expert) :\n",
    "    expert_data = getExpertData(expert)\n",
    "    observations, actions, returns = expert_data.values()\n",
    "    #Reshaping action to 2d\n",
    "    actions = actions.reshape((actions.shape[0], actions.shape[-1]))\n",
    "    #Train-validation split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(observations, actions, test_size = 0.1, random_state = 1)\n",
    "    \n",
    "    return(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def behaviorCloning(observations, actions, lr = 0.001, epochs = 10, batch_size = 100) :\n",
    "    #Getting shapes which are used in input and output layers of the network\n",
    "    obs_shape = observations.shape\n",
    "    act_shape = actions.shape\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape = obs_shape[1:]))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(units = 32, activation = \"relu\"))\n",
    "    model.add(Dense(units = 32, activation = \"relu\"))\n",
    "    model.add(Dense(units = act_shape[-1]))\n",
    "    \n",
    "    optimizer = Adam(lr)\n",
    "    \n",
    "    model.compile(optimizer = optimizer, loss = \"mse\", metrics = [\"mse\"])\n",
    "    \n",
    "    model.fit(x = observations, y = actions, epochs = epochs, batch_size = batch_size, verbose = 0)\n",
    "\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nparams = {\"lr\" : [0.001, 0.01, 0.1], \"epochs\" : [10, 20, 50]}\\nbatch_size = 100\\nvalidation_results = defaultdict(list)\\nfor expert in experts :\\n    print(\"Expert : {}\".format(expert))\\n    X_train, X_test, y_train, y_test = prepareData(expert)\\n    for parameters in tqdm_notebook(ParameterGrid(params), desc = \"Parameter Grid\") :\\n        lr, epochs = parameters[\"lr\"], parameters[\"epochs\"]\\n        model = behaviorCloning(X_train, y_train, lr, epochs, batch_size)\\n        res = model.evaluate(X_test, y_test, verbose = 0)\\n        validation_results[expert].append((lr, epochs, batch_size, res[0]))\\n'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "params = {\"lr\" : [0.001, 0.01, 0.1], \"epochs\" : [10, 20, 50]}\n",
    "batch_size = 100\n",
    "validation_results = defaultdict(list)\n",
    "for expert in experts :\n",
    "    print(\"Expert : {}\".format(expert))\n",
    "    X_train, X_test, y_train, y_test = prepareData(expert)\n",
    "    for parameters in tqdm_notebook(ParameterGrid(params), desc = \"Parameter Grid\") :\n",
    "        lr, epochs = parameters[\"lr\"], parameters[\"epochs\"]\n",
    "        model = behaviorCloning(X_train, y_train, lr, epochs, batch_size)\n",
    "        res = model.evaluate(X_test, y_test, verbose = 0)\n",
    "        validation_results[expert].append((lr, epochs, batch_size, res[0]))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getReturns(expert, model, rollouts) :\n",
    "    model_returns = []\n",
    "    env = gym.make(expert)\n",
    "    max_steps = env.spec.timestep_limit\n",
    "    for i in range(rollouts):\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "        totalr = 0.\n",
    "        steps = 0\n",
    "        while not done:\n",
    "            obs = obs.reshape((1, obs.shape[0]))\n",
    "            action = model.predict(obs)\n",
    "            action = action.reshape((action.shape[0], 1, action.shape[1]))\n",
    "            obs, r, done, _ = env.step(action)\n",
    "            totalr += r\n",
    "            steps += 1\n",
    "            if steps >= max_steps:\n",
    "                    break\n",
    "        model_returns.append(totalr)\n",
    "    return(model_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expert : Walker2d-v2"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for expert in experts :\n",
    "    print(\"\\rExpert : {}\".format(expert), end = \"\")\n",
    "    expert_data = getExpertData(expert)\n",
    "    observations, actions, expert_returns = expert_data[\"observations\"], expert_data[\"actions\"], expert_data[\"returns\"]\n",
    "    actions = np.squeeze(actions)\n",
    "    model = behaviorCloning(observations, actions, lr = 0.001, epochs = 20, batch_size = 100)\n",
    "    model_returns = getReturns(expert, model, 20)\n",
    "    results.append([expert, np.mean(expert_returns), np.mean(model_returns), np.std(expert_returns), np.std(model_returns)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Expert</th>\n",
       "      <th>Mean Expert Returns</th>\n",
       "      <th>Mean Model Returns</th>\n",
       "      <th>Std Expert Returns</th>\n",
       "      <th>Std Model Returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ant-v2</td>\n",
       "      <td>4643.365419</td>\n",
       "      <td>4715.059918</td>\n",
       "      <td>721.400246</td>\n",
       "      <td>100.725479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HalfCheetah-v2</td>\n",
       "      <td>4148.390453</td>\n",
       "      <td>3888.772914</td>\n",
       "      <td>93.052040</td>\n",
       "      <td>81.794357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hopper-v2</td>\n",
       "      <td>3777.427432</td>\n",
       "      <td>634.488760</td>\n",
       "      <td>3.983109</td>\n",
       "      <td>6.815471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Humanoid-v2</td>\n",
       "      <td>10414.474915</td>\n",
       "      <td>1280.554422</td>\n",
       "      <td>49.053790</td>\n",
       "      <td>946.155600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reacher-v2</td>\n",
       "      <td>-3.484670</td>\n",
       "      <td>-12.215830</td>\n",
       "      <td>1.929408</td>\n",
       "      <td>2.441112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Walker2d-v2</td>\n",
       "      <td>5515.393810</td>\n",
       "      <td>771.369222</td>\n",
       "      <td>57.088761</td>\n",
       "      <td>458.843686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Expert  Mean Expert Returns  Mean Model Returns  \\\n",
       "0          Ant-v2          4643.365419         4715.059918   \n",
       "1  HalfCheetah-v2          4148.390453         3888.772914   \n",
       "2       Hopper-v2          3777.427432          634.488760   \n",
       "3     Humanoid-v2         10414.474915         1280.554422   \n",
       "4      Reacher-v2            -3.484670          -12.215830   \n",
       "5     Walker2d-v2          5515.393810          771.369222   \n",
       "\n",
       "   Std Expert Returns  Std Model Returns  \n",
       "0          721.400246         100.725479  \n",
       "1           93.052040          81.794357  \n",
       "2            3.983109           6.815471  \n",
       "3           49.053790         946.155600  \n",
       "4            1.929408           2.441112  \n",
       "5           57.088761         458.843686  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(results, columns = [\"Expert\", \"Mean Expert Returns\", \"Mean Model Returns\", \"Std Expert Returns\", \"Std Model Returns\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"expert_data/behaviorcloning_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DAgger Algorithm :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DAgger(expert, observations, actions, parameters, iterations) :\n",
    "    obs_dataset = []\n",
    "    act_dataset = []\n",
    "    rewards = []\n",
    "    lr, epochs, batch_size = parameters[\"lr\"], parameters[\"epochs\"], parameters[\"batch_size\"]\n",
    "    train_observations, train_actions = observations, actions\n",
    "    for i in tqdm_notebook(range(iterations), desc = \"DAgger Iteration\") :\n",
    "        #Train model on training set D\n",
    "        model = behaviorCloning(train_observations, train_actions, lr, epochs, batch_size)\n",
    "        env = gym.make(expert)\n",
    "        max_steps = env.spec.timestep_limit\n",
    "        \n",
    "        #Using trained model to get mean rewards\n",
    "        rollouts = 20\n",
    "        returns = []\n",
    "        for j in range(rollouts):\n",
    "            obs = env.reset()\n",
    "            done = False\n",
    "            totalr = 0.\n",
    "            steps = 0\n",
    "            while not done:\n",
    "                obs = obs.reshape((1, obs.shape[0]))\n",
    "                model_action = model.predict(obs)\n",
    "                model_action = model_action.reshape((model_action.shape[0], 1, model_action.shape[1]))\n",
    "                obs, r, done, _ = env.step(model_action)\n",
    "                totalr += r\n",
    "                steps += 1\n",
    "                if steps >= max_steps:\n",
    "                    break\n",
    "            returns.append(totalr)\n",
    "        rewards.append(returns)\n",
    "        \n",
    "        \n",
    "        #Start with initial observation and run model to get [o1, o2, o3]\n",
    "        new_observations = []\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "        steps = 0\n",
    "        while not done:\n",
    "            new_observations.append(obs)\n",
    "            obs = obs.reshape((1, obs.shape[0]))\n",
    "            model_action = model.predict(obs)\n",
    "            model_action = model_action.reshape((model_action.shape[0], 1, model_action.shape[1]))\n",
    "            obs, r, done, _ = env.step(model_action)\n",
    "            steps += 1\n",
    "            if steps >= max_steps:\n",
    "                break\n",
    "                    \n",
    "        #Keeping track of rewards\n",
    "        #rewards.append(totalr)\n",
    "        \n",
    "        #Use these observations as input to expert and get expert actions\n",
    "        with tf.Session() :\n",
    "            env = gym.make(expert)\n",
    "            policy_fn = load_policy.load_policy(\"experts/{}.pkl\".format(expert))\n",
    "            new_actions = []\n",
    "\n",
    "            for nobs in new_observations :\n",
    "                expert_action = policy_fn(nobs[None,:])\n",
    "                new_actions.append(expert_action)\n",
    "            \n",
    "        #Get labeled set D_exp = [(o1, a1), (o2, a2), ...]\n",
    "        #Aggregate this to training set (D = D + D_exp) and retrain model\n",
    "        obs_dataset.append(train_observations)\n",
    "        act_dataset.append(train_actions)\n",
    "        train_observations = np.concatenate((train_observations, np.array(new_observations)))\n",
    "        train_actions = np.concatenate((train_actions, np.squeeze(np.array(new_actions))))\n",
    "        \n",
    "    return(obs_dataset, act_dataset, rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running DAgger for Hopper-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e0e5e0d9e9b4c878b13a00b7f9b211f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='DAgger Iteration', max=20, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs (1, 11) (1, 11)\n",
      "obs (1, 11) (1, 11)\n",
      "obs (1, 11) (1, 11)\n",
      "obs (1, 11) (1, 11)\n",
      "obs (1, 11) (1, 11)\n",
      "obs (1, 11) (1, 11)\n",
      "obs (1, 11) (1, 11)\n",
      "obs (1, 11) (1, 11)\n",
      "obs (1, 11) (1, 11)\n",
      "obs (1, 11) (1, 11)\n",
      "obs (1, 11) (1, 11)\n",
      "obs (1, 11) (1, 11)\n",
      "obs (1, 11) (1, 11)\n",
      "obs (1, 11) (1, 11)\n",
      "obs (1, 11) (1, 11)\n",
      "obs (1, 11) (1, 11)\n",
      "obs (1, 11) (1, 11)\n",
      "obs (1, 11) (1, 11)\n",
      "obs (1, 11) (1, 11)\n",
      "obs (1, 11) (1, 11)\n"
     ]
    }
   ],
   "source": [
    "expert = \"Hopper-v2\"\n",
    "expert_data = getExpertData(expert)\n",
    "observations, actions, expert_returns = expert_data[\"observations\"], expert_data[\"actions\"], expert_data[\"returns\"]\n",
    "actions = np.squeeze(actions)\n",
    "obs_dataset, act_dataset, rewards = DAgger(expert, observations, actions, {\"lr\" : 0.001, \"epochs\" : 20, \"batch_size\" : 100}, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import sem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', family = \"serif\")\n",
    "plt.rc('xtick', labelsize='x-small')\n",
    "plt.rc('ytick', labelsize='x-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean_rewards = [np.mean(rollout_rewards) for rollout_rewards in rewards]\n",
    "stderr_rewards = [sem(rollout_rewards) for rollout_rewards in rewards]\n",
    "expert_performance = df[df[\"Expert\"] == \"Hopper-v2\"][\"Mean Expert Returns\"].values[0]\n",
    "bc_performance = df[df[\"Expert\"] == \"Hopper-v2\"][\"Mean Model Returns\"].values[0]\n",
    "x = np.arange(1, 21, 1)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (4, 3))\n",
    "ax.errorbar(x, mean_rewards, fmt = \"o\", yerr = stderr_rewards, ecolor = \"black\", mfc = \"None\", markersize = 4, mec = \"blue\", capsize = 2, alpha = 0.7, mew = 0.7, elinewidth = 0.7)\n",
    "ax.plot([1, 21], [expert_performance, expert_performance], linestyle = \"--\", color = \"green\", linewidth = 0.7)\n",
    "ax.plot([1, 21], [bc_performance, bc_performance], linestyle = \"--\", color = \"red\", linewidth = 0.7)\n",
    "ax.set_xlabel(\"Dagger Iterations\")\n",
    "ax.set_ylabel(\"Mean Reward\")\n",
    "ax.set_xticks(np.arange(0, 23, 2))\n",
    "fig.savefig(\"Hopper-v2-dagger.png\", bbox_inches = \"tight\", dpi = 300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
